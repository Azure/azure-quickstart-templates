#
# Copyright (c) 2020, SAS Institute Inc., Cary, NC, USA.  All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0
#
---
- name: Distribute ssh key to Hadoop nodes for AzureUser
  hosts: [va_controllers,va_workers]
  become_user: AzureUser
  become: yes
  tasks:
  - name: Copy ssh key from jumpvm to Hadoop nodes for AzureUser
    copy:
      src: ~/.ssh
      dest: $HOME
      mode: preserve

- name: Distribute ssh key to Hadoop nodes for sasinst
  hosts: [va_controllers,va_workers]
  become_user: sasinst
  become: yes
  tasks:
  - name: Copy ssh key from jumpvm to Hadoop nodes for sasinst
    copy:
      src: ~/.ssh
      dest: $HOME
      mode: preserve

- name: Installing all updates with zypper
  hosts: [va_controllers,va_workers]
  become_user: root
  become: yes
  gather_facts: false
  tasks:
  - name: Doing the update
    zypper:
      name: '*'
      state: latest

  - name: Install required packages
    package:
      name: "{{ item }}"
      state: latest
    loop:
      - java-1_8_0-openjdk

# GWB: Commenting out this step. It doesn't appear necessary, as
# all nodes in the hadoop cluster can find each other.
#
# Forcing IP addresses into /etc/hosts will make it much harder to
# delete or add additional nodes to the cluster after the deployment.
#
#  - name: Host file update - Local DNS setup across all the Hadoop servers
#    hosts: [va_controllers,va_workers]
#    gather_facts: yes
#    tasks:
#    - name: Update the /etc/hosts file with IP address and hostname
#      become: yes
#      become_user: root
#      lineinfile:
#        path: "/etc/hosts"
#        line: "{{ hostvars[item]['ansible_env'].SSH_CONNECTION.split(' ')[2] }}\t{{ hostvars[item]['ansible_hostname']}}\t{{ hostvars[item]['ansible_hostname']}}"
#        state: present
#        backup: yes
#      with_items: "{{ groups['va_controllers'] }},{{ groups['va_workers'] }}"

- name: Download Hadoop on nameNode and dataNodes
  hosts: [va_controllers,va_workers]
  become_user: sasinst
  become: yes
  vars:
    HADOOP_VERSION: 3.1.4
    HADOOP_HOME: "/sas/hadoop"
  tasks:
  - name: Make hadoop home dirctory
    become: yes
    file:
      path: "{{ HADOOP_HOME }}"
      state: directory
      mode: '0755'

  - name: Downloading Hadoop from Apache
    become: yes
    unarchive:
      remote_src: yes
      src: "https://downloads.apache.org/hadoop/core/hadoop-{{ HADOOP_VERSION }}/hadoop-{{ HADOOP_VERSION }}.tar.gz"
      dest: "{{ HADOOP_HOME }}"
      extra_opts: [--strip-components=1]
    register: task_result
    until: task_result is success
    retries: 10
    delay: 5

- name: Setup environment on nameNode (master)
  hosts: [va_controllers]
  become_user: sasinst
  become: yes
  vars:
    HADOOP_HOME: "/sas/hadoop"
  tasks:
  - name: Insert Hadoop environment into bashrc
    blockinfile:
      marker: "## {mark} added by ansible (install_hadoop)"
      dest: "$HOME/.bashrc"
      backup: yes
      block: |
        export HADOOP_HOME={{ HADOOP_HOME }}
        export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
        export HADOOP_MAPRED_HOME=$HADOOP_HOME
        export HADOOP_COMMON_HOME=$HADOOP_HOME
        export HADOOP_HDFS_HOME=$HADOOP_HOME
        export YARN_HOME=$HADOOP_HOME
        export HDFS_NAMENODE_USER="sasinst"
        export HDFS_DATANODE_USER="sasinst"
        export HDFS_SECONDARYNAMENODE_USER="sasinst"
        export YARN_RESOURCEMANAGER_USER="sasinst"
        export YARN_NODEMANAGER_USER="sasinst"
        export JAVA_HOME=/usr/lib64/jvm/jre-1.8.0-openjdk
        export PATH=$JAVA_HOME:$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
      insertafter: EOF
      create: yes

  - name: Edit hadoop-env.sh configuration
    blockinfile:
      marker: "## {mark} added by ansible (install_hadoop)"
      path: "{{ HADOOP_HOME }}/etc/hadoop/hadoop-env.sh"
      insertafter: "# export JAVA_HOME="
      block: |
        export JAVA_HOME=/usr/lib64/jvm/jre-1.8.0-openjdk

  - name: Edit core-site.xml configuration
    blockinfile:
      marker: "## {mark} added by ansible (install_hadoop)"
      path: "{{ HADOOP_HOME }}/etc/hadoop/core-site.xml"
      insertafter: "<configuration>"
      block: |
        <property>
          <name>fs.default.name</name>
          <value>hdfs://{{ inventory_hostname }}:9000</value>
        </property>

  - name: Edit hdfs-site.xml configuration
    blockinfile:
      marker: "## {mark} added by ansible (install_hadoop)"
      path: "{{ HADOOP_HOME }}/etc/hadoop/hdfs-site.xml"
      insertafter: "<configuration>"
      block: |
        <property>
          <name>dfs.namenode.name.dir</name>
          <value>/sas/hadoop_data/nameNode</value>
        </property>
        <property>
          <name>dfs.datanode.data.dir</name>
          <value>/sas/hadoop_data/dataNode</value>
        </property>
        <property>
          <name>dfs.replication</name>
          <value>2</value>
        </property>

  - name: Edit mapred-site.xml configuration
    blockinfile:
      marker: "## {mark} added by ansible (install_hadoop)"
      path: "{{ HADOOP_HOME }}/etc/hadoop/mapred-site.xml"
      insertafter: "<configuration>"
      block: |
        <property>
          <name>mapreduce.framework.name</name>
          <value>yarn</value>
        </property>
        <property>
          <name>yarn.app.mapreduce.am.env</name>
          <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
        </property>
        <property>
          <name>mapreduce.map.env</name>
          <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
        </property>
        <property>
          <name>mapreduce.reduce.env</name>
          <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
        </property>
        <property>
          <name>yarn.app.mapreduce.am.resource.mb</name>
          <value>512</value>
        </property>
        <property>
          <name>mapreduce.map.memory.mb</name>
          <value>256</value>
        </property>
        <property>
          <name>mapreduce.reduce.memory.mb</name>
          <value>256</value>
        </property>

  - name: Edit yarn-site.xml configuration
    blockinfile:
      marker: "## {mark} added by ansible (install_hadoop)"
      path: "{{ HADOOP_HOME }}/etc/hadoop/yarn-site.xml"
      insertafter: "<configuration>"
      block: |
        <property>
          <name>yarn.acl.enable</name>
          <value>0</value>
        </property>
        <property>
          <name>yarn.resourcemanager.hostname</name>
          <value>{{ ansible_eth0.ipv4.address }}</value>
        </property>
        <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
        </property>
        <property>
          <name>yarn.nodemanager.resource.memory-mb</name>
          <value>2048</value>
        </property>
        <property>
          <name>yarn.scheduler.maximum-allocation-mb</name>
          <value>2048</value>
        </property>
        <property>
          <name>yarn.scheduler.minimum-allocation-mb</name>
          <value>1024</value>
        </property>
        <property>
          <name>yarn.nodemanager.vmem-check-enabled</name>
          <value>false</value>
        </property>
        # The last property disables virtual-memory checking which can prevent containers from being allocated properly with openjdk if enabled.
        # Note: Memory allocation can be tricky on low RAM nodes because default values are not suitable for nodes with less than 8GB of RAM.
        #       We have manually set memory allocation for MapReduce jobs, and provide a sample configuration for 4GB RAM nodes.

  - name: Make sure localhost is not in the workers file
    lineinfile:
      path: "{{ HADOOP_HOME }}/etc/hadoop/workers"
      state: absent
      regexp: '^localhost'

  - name: Add worker nodes to workers file
    become: yes
    lineinfile:
      path: "{{ HADOOP_HOME }}/etc/hadoop/workers"
      line: "{{ hostvars[item]['inventory_hostname']}}"
      state: present
      backup: yes
    with_items: "{{ groups['va_workers'] }}"

- name: Distribute Hadoop configuration to work nodes
  hosts: [va_workers]
  become_user: sasinst
  become: yes
  tasks:
  - name: Copy Hadoop configuration files to worker nodes
    synchronize: src=/sas/hadoop/etc/hadoop/ dest=/sas/hadoop/etc/hadoop
    delegate_to: vacontroller

- name: Start Hadoop
  hosts: [va_controllers]
  become_user: sasinst
  become: yes
  vars:
    HADOOP_HOME: "/sas/hadoop"
  tasks:
  - name: Format hdfs on namenode
    become: yes
    shell: |-
      {{ HADOOP_HOME }}/bin/hdfs namenode -format

  - name: Start dfs
    become: yes
    shell: |-
      {{ HADOOP_HOME }}/sbin/start-dfs.sh
